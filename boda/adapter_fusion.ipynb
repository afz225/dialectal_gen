{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from copy import copy\n",
    "from transformers import AutoTokenizer\n",
    "from dataclasses import dataclass\n",
    "from transformers.tokenization_utils_base import PreTrainedTokenizerBase, PaddingStrategy\n",
    "from typing import Optional, Union\n",
    "import os\n",
    "from math import inf\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForMultipleChoice\n",
    "from adapters import init,AutoAdapterModel\n",
    "import numpy as np\n",
    "from transformers import TrainingArguments, EvalPrediction\n",
    "from adapters import AdapterTrainer\n",
    "import pandas as pd\n",
    "from adapters import AdapterSetup, AutoAdapterModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    # Repeat each prompt for 5 times to go with the 5 possibilities of each option\n",
    "    first_sentences = [[context] * 2 for context in examples[\"startphrase\"]]\n",
    "    # Grab all options\n",
    "    second_sentences = [[ending1, examples['ending2'][i]] for i, ending1 in enumerate(examples['ending1'])]\n",
    "#     print(first_sentences)\n",
    "#     print(\"====\")\n",
    "\n",
    "    # Flatten everything\n",
    "    first_sentences = sum(first_sentences, [])\n",
    "    second_sentences = sum(second_sentences, [])\n",
    "\n",
    "#     print(first_sentences)\n",
    "#     print(\"====\")\n",
    "#     print(second_sentences)\n",
    "\n",
    "    # Tokenize\n",
    "    tokenized_examples = tokenizer(first_sentences, second_sentences, truncation=True)\n",
    "    # Un-flatten\n",
    "    return {\n",
    "        k: [v[i : i + 2] for i in range(0, len(v), 2)]\n",
    "        for k, v in tokenized_examples.items()\n",
    "    }\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorForMultipleChoice:\n",
    "    \"\"\"\n",
    "    Data collator that will dynamically pad the inputs for multiple choice received.\n",
    "    \"\"\"\n",
    "\n",
    "    tokenizer: AutoTokenizer\n",
    "    padding: Union[bool, str, PaddingStrategy] = True\n",
    "    max_length: Optional[int] = None\n",
    "    pad_to_multiple_of: Optional[int] = None\n",
    "\n",
    "    def __call__(self, features):\n",
    "        label_name = \"label\" if \"label\" in features[0].keys() else \"labels\"\n",
    "        labels = [feature.pop(label_name) for feature in features]\n",
    "        batch_size = len(features)\n",
    "        num_choices = len(features[0][\"input_ids\"])\n",
    "        flattened_features = [\n",
    "            [{k: v[i] for k, v in feature.items()} for i in range(num_choices)] for feature in features\n",
    "        ]\n",
    "        flattened_features = sum(flattened_features, [])\n",
    "\n",
    "        batch = self.tokenizer.pad(\n",
    "            flattened_features,\n",
    "            padding=self.padding,\n",
    "            max_length=self.max_length,\n",
    "            pad_to_multiple_of=self.pad_to_multiple_of,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        batch = {k: v.view(batch_size, num_choices, -1) for k, v in batch.items()}\n",
    "        batch[\"labels\"] = torch.tensor(labels, dtype=torch.int64)\n",
    "        return batch\n",
    "    \n",
    "def compute_accuracy(p: EvalPrediction):\n",
    "  preds = np.argmax(p.predictions, axis=1)\n",
    "  return {\"acc\": (preds == p.label_ids).mean()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dialects = [\"std-dia\", \"aus\", \"hon\", \"nig\", \"col\", \"wel\"]\n",
    "train_dialects = [\"std-dia\", \"aus\", \"hon\", \"nig\", \"col\" ]\n",
    "test_dialects =[\"wel\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForMultipleChoice were not initialized from the model checkpoint at FacebookAI/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"FacebookAI/xlm-roberta-base\")\n",
    "\n",
    "\n",
    "# model = AutoAdapterModel.from_pretrained(\"FacebookAI/xlm-roberta-base\")\n",
    "model = AutoModelForMultipleChoice.from_pretrained(\"FacebookAI/xlm-roberta-base\")\n",
    "# Enable adapter support\n",
    "init(model) \n",
    "\n",
    "\n",
    "##############3 Load adapters \n",
    "for dialect in train_dialects:\n",
    "    model.load_adapter(f\"/l/users/abdelrahman.sadallah/dialectal_gen/{dialect}-adapter-figqa-xlmr\", config='seq_bn', with_head=False)\n",
    "\n",
    "\n",
    "\n",
    "model.add_adapter_fusion(train_dialects, \"dynamic\")\n",
    "model.train_adapter_fusion(train_dialects)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XLMRobertaForMultipleChoice(\n",
       "  (roberta): XLMRobertaModel(\n",
       "    (embeddings): XLMRobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(250002, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): XLMRobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttentionWithAdapters(\n",
       "              (query): LoRALinearTorch(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (key): LoRALinearTorch(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (value): LoRALinearTorch(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (prefix_tuning): PrefixTuningLayer(\n",
       "                (prefix_gates): ModuleDict()\n",
       "                (pool): PrefixTuningPool(\n",
       "                  (prefix_tunings): ModuleDict()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutputWithAdapters(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): LoRALinearTorch(\n",
       "              in_features=768, out_features=3072, bias=True\n",
       "              (loras): ModuleDict()\n",
       "            )\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutputWithAdapters(\n",
       "            (dense): LoRALinearTorch(\n",
       "              in_features=3072, out_features=768, bias=True\n",
       "              (loras): ModuleDict()\n",
       "            )\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (adapters): ModuleDict(\n",
       "              (std-dia): Adapter(\n",
       "                (non_linearity): Activation_Function_Class(\n",
       "                  (f): ReLU()\n",
       "                )\n",
       "                (adapter_down): Sequential(\n",
       "                  (0): Linear(in_features=768, out_features=48, bias=True)\n",
       "                  (1): Activation_Function_Class(\n",
       "                    (f): ReLU()\n",
       "                  )\n",
       "                )\n",
       "                (adapter_up): Linear(in_features=48, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (aus): Adapter(\n",
       "                (non_linearity): Activation_Function_Class(\n",
       "                  (f): ReLU()\n",
       "                )\n",
       "                (adapter_down): Sequential(\n",
       "                  (0): Linear(in_features=768, out_features=48, bias=True)\n",
       "                  (1): Activation_Function_Class(\n",
       "                    (f): ReLU()\n",
       "                  )\n",
       "                )\n",
       "                (adapter_up): Linear(in_features=48, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (hon): Adapter(\n",
       "                (non_linearity): Activation_Function_Class(\n",
       "                  (f): ReLU()\n",
       "                )\n",
       "                (adapter_down): Sequential(\n",
       "                  (0): Linear(in_features=768, out_features=48, bias=True)\n",
       "                  (1): Activation_Function_Class(\n",
       "                    (f): ReLU()\n",
       "                  )\n",
       "                )\n",
       "                (adapter_up): Linear(in_features=48, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (nig): Adapter(\n",
       "                (non_linearity): Activation_Function_Class(\n",
       "                  (f): ReLU()\n",
       "                )\n",
       "                (adapter_down): Sequential(\n",
       "                  (0): Linear(in_features=768, out_features=48, bias=True)\n",
       "                  (1): Activation_Function_Class(\n",
       "                    (f): ReLU()\n",
       "                  )\n",
       "                )\n",
       "                (adapter_up): Linear(in_features=48, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (col): Adapter(\n",
       "                (non_linearity): Activation_Function_Class(\n",
       "                  (f): ReLU()\n",
       "                )\n",
       "                (adapter_down): Sequential(\n",
       "                  (0): Linear(in_features=768, out_features=48, bias=True)\n",
       "                  (1): Activation_Function_Class(\n",
       "                    (f): ReLU()\n",
       "                  )\n",
       "                )\n",
       "                (adapter_up): Linear(in_features=48, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (adapter_fusion_layer): ModuleDict(\n",
       "              (std-dia,aus,hon,nig,col): BertFusion(\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): XLMRobertaPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "    (shared_parameters): ModuleDict()\n",
       "    (invertible_adapters): ModuleDict()\n",
       "    (prefix_tuning): PrefixTuningPool(\n",
       "      (prefix_tunings): ModuleDict()\n",
       "    )\n",
       "    (prompt_tuning): PromptTuningLayer(\n",
       "      (base_model_embeddings): Embedding(250002, 768, padding_idx=1)\n",
       "      (prompt_tunings): ModuleDict()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialect = 'wel'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if dialect != \"std-dia\":\n",
    "    # ds = load_dataset(\"ashabrawy/dia_copa\", dialect, cache_dir=\"/scratch/afz225/.cache\")\n",
    "    ds = load_dataset(\"ashabrawy/dia_figqa\", dialect)\n",
    "    columns = copy(ds['train'].column_names)\n",
    "    # columns.remove('label')\n",
    "    columns.remove('labels')\n",
    "    ds = ds.map(preprocess_function, batched=True, remove_columns=columns)\n",
    "    # ds = ds.rename_column(original_column_name=\"label\", new_column_name=\"labels\")\n",
    "    # ds.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "\n",
    "else:\n",
    "    # eval_ds = load_dataset(\"super_glue\", \"copa\", cache_dir=\"/scratch/afz225/.cache\")['validation']\n",
    "    ds = load_dataset(\"nightingal3/fig-qa\")\n",
    "    columns = copy(ds.column_names)\n",
    "    # columns.remove('label')\n",
    "    columns.remove('labels')\n",
    "    ds = ds.map(preprocess_function, batched=True, remove_columns=columns)\n",
    "    # eval_ds = eval_ds.rename_column(original_column_name=\"label\", new_column_name=\"labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abdelrahman.sadallah/mambaforge/envs/nlp/lib/python3.10/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n",
      "Detected kernel version 5.4.204, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "You're using a XLMRobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3630' max='3630' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3630/3630 02:28, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.692500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.694700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.695800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.694200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.692700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.694100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.694000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.693500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.694200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.694200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.693600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.695200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.694600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.693300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.693900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.693400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.694200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.693100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3630, training_loss=0.693947418465102, metrics={'train_runtime': 148.6655, 'train_samples_per_second': 390.433, 'train_steps_per_second': 24.417, 'total_flos': 2909516737191936.0, 'train_loss': 0.693947418465102, 'epoch': 6.0})"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# model.add_classification_head(\n",
    "#     dialect,\n",
    "#     num_labels=2,\n",
    "#     overwrite_ok=True\n",
    "# )\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    learning_rate=1e-4,\n",
    "    num_train_epochs=6,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=32,\n",
    "    logging_steps=200,\n",
    "    output_dir=f\"/l/users/abdelrahman.sadallah/dialectal_gen-adapterfusion-{dialect}\",\n",
    "    overwrite_output_dir=True,\n",
    "    # The next line is important to ensure the dataset labels are properly passed to the model\n",
    "    remove_unused_columns=False,\n",
    ")\n",
    "trainer = AdapterTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=ds[\"train\"],\n",
    "    eval_dataset=ds[\"validation\"],\n",
    "    compute_metrics=compute_accuracy,\n",
    "    data_collator=DataCollatorForMultipleChoice(tokenizer=tokenizer),\n",
    ")\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='35' max='35' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [35/35 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   eval_loss  eval_acc  eval_runtime  eval_samples_per_second  \\\n",
      "0    0.69315  0.499086         1.544                   708.56   \n",
      "\n",
      "   eval_steps_per_second  epoch test_set  \n",
      "0                 22.669    6.0      wel  \n"
     ]
    }
   ],
   "source": [
    "model.save_adapter_fusion(f\"/l/users/abdelrahman.sadallah/dialectal_gen/{dialect}-adapterfusion-figqa-xlmr\", train_dialects, with_head=False)\n",
    "\n",
    "\n",
    "eval_metrics = trainer.evaluate(ds[\"validation\"])\n",
    "eval_metrics['test_set'] = dialect\n",
    "\n",
    "results = pd.DataFrame(eval_metrics, index=[0])\n",
    "\n",
    "print(results)\n",
    "results.to_csv(f\"{dialect}-adapterfusion-figqa-xlmr.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
